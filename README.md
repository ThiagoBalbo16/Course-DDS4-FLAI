# Course-DDS4-FLAI

'Dominando Data Science' (DDS) is a problem-solving course offered in 8 weeks by [FLAI](https://www.flai.com.br/). It includes a large range of topics and tools for students that are interested in pursuing a career in data science. Briefly, it comprises some of the skills for machine learning:

- Python 
- Linear regression
- Logistic regression
- K-Nearest Neighbor (KNN) 
- Tree Decision
- Bagging
- Random Forest
- Hyperparameter Tuning


## Class 05

<div align="justify">In this class there is the basic about python programming language (objects attributes, lists, operators, booleans, functions, conditional statements, 
iterators, Numpy, etc.) and a project regarding questions about completing a sticker album, such as the average cost, the average number of stickers, the probability to spend less than $1500, among other analysis.
</dev>

## Class 06

In this class is developed basic algorithms using the Library Pandas, 
which allows to work with data.frames, to make exploratory data analysis, etc.  

## Class 07

<div align="justify">
In this class is developed the first machine learning model in the course. It has used health insurance data (categorical variables about smoking and gender, charges, bmi, etc.)
and comprises exploratory analysis,
data treatment, linear regression fitting, Mean Squared Error (MSE) and Mean Absolute Error (MAE) evaluation, Holdout Validation, and so on.
</dev>

## Class 08

<div align="justify">
In this class was used the health insurance data as well. It has enhanced the last model by applying the Repeated Holdout Validation,
K-Nearest Neighbor (KNN) and Tree Decision models. 
</dev>

## Class 09


<div align="justify">
In this class it has still used the health insurance data, upgrading the last results by applying Logistic Regression and K-Fold Cross Validation.
</dev>

## Class 10

<div align="justify">
In this class, it was further improved the health insurance analysis by using Repeated K-Fold Validation, Hard and Soft Votes,
Bagging and Random Forest Models.
</dev>

## Class 11

<div align="justify">
In this class, it was used a company's dataset to predict customer's exits, a churn modeling.
For this purpose, it was applied the developed techniques in the last classes, such as exploratory analysis, data treatment, a combined machine learning analysis 
with linear regression, logistic regression, KNN, Tree Decision, 
Bagging, Random Forest, Stratified K-Fold, accuracy/sensitivity/precision/balanced_accuracy/f1-score ranking, etc.
 </dev>
 
 ## Class 12
 
In this class, it was used data from the Titanic accident to predict passangers' probabilities of survival. For this reason, it was applied the random forest model and the parameters were optimized by hyperparameter tuning.
